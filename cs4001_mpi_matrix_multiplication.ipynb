{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidfague/parallel-neuron/blob/main/cs4001_mpi_matrix_multiplication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5coBMenZSv7"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/cyneuro/CI-BioEng-Class/blob/main/cs4001_mpi.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o4lGpxaxXxW"
      },
      "source": [
        "# Introduction to MPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJuFl0onxkSz"
      },
      "source": [
        "## Homework:\n",
        "\n",
        "1. Review the MPI parallelization of the matrix multiplication problem in [this tutorial](https://afzalbadshah.medium.com/matrix-multiplication-on-multiple-processors-mpi4py-dce0cb4a6d53).\n",
        "2. Using the code above, write a function which can multiply 2 random $N\\times N$ matrices.\n",
        "3. Select 3-4 values of $N$ (e.g., $N =$ 10, 100, 500, 1000) and record multiplication time in the following scenarios:\n",
        "    - Serial multiplication on a PC.\n",
        "    - Parallel multiplication on a PC.\n",
        "    - Parallel multiplication in Colab.\n",
        "    - Parallel multiplication on FABRIC / ACCESS / CloudLab / Hellbender.\n",
        "\n",
        "Plot the simulation time dynamics of these scenarios on the same graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOdnjrXRa4hw",
        "outputId": "f7b5e330-645a-4ade-bfe3-8b56a0f8efb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.0.3.tar.gz (466 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.3/466.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.3-cp311-cp311-linux_x86_64.whl size=4458236 sha256=3102303d9ebb2ca169e980d1e807fa65068bfaa1b743cb711cd652a82980b476\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/56/17/bf6ba37aa971a191a8b9eaa188bf5ec855b8911c1c56fb1f84\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install mpi4py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tBeJMKXJZ5KR"
      },
      "outputs": [],
      "source": [
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7gnskrBVaBCW"
      },
      "outputs": [],
      "source": [
        "# Function to perform matrix multiplication\n",
        "def matrix_multiply(A, B):\n",
        "    C = np.zeros((A.shape[0], B.shape[1]))\n",
        "    for i in range(A.shape[0]):\n",
        "        for j in range(B.shape[1]):\n",
        "            for k in range(A.shape[1]):\n",
        "                C[i][j] += A[i][k] * B[k][j]\n",
        "    return C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mpaZRzy2aDkX"
      },
      "outputs": [],
      "source": [
        "# Initialize MPI\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pb0rSW1xZNt",
        "outputId": "ac863cfe-85f4-43c5-877c-cdb7e257236c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.0025856494903564453 seconds for N = 10\n",
            "Execution time: 0.961047887802124 seconds for N = 100\n",
            "Execution time: 141.30803632736206 seconds for N = 500\n",
            "Execution time: 1112.2218866348267 seconds for N = 1000\n",
            "Execution time: 0.0017328262329101562 seconds for N = 10\n",
            "Execution time: 0.9827353954315186 seconds for N = 100\n",
            "Execution time: 139.39754366874695 seconds for N = 500\n",
            "Execution time: 1126.6178255081177 seconds for N = 1000\n"
          ]
        }
      ],
      "source": [
        "location = 'Google Colab'\n",
        "Ns = [10,100,500,1000]\n",
        "times = []\n",
        "parallels = []\n",
        "locations = []\n",
        "parallel_options = [False, True]\n",
        "for parallel in parallel_options:\n",
        "  for N in Ns:\n",
        "    start_time = time.time()\n",
        "    if parallel:\n",
        "      # Master process\n",
        "      if rank == 0:\n",
        "          # Generate matrices A and B\n",
        "          A = np.random.rand(N, N)\n",
        "          B = np.random.rand(N, N)\n",
        "\n",
        "          # Split matrices for distribution\n",
        "          chunk_size = A.shape[0] // size\n",
        "          A_chunks = [A[i:i+chunk_size] for i in range(0, A.shape[0], chunk_size)]\n",
        "\n",
        "          # Send parts of A and B to worker processes\n",
        "          for i in range(1, size):\n",
        "              comm.send(A_chunks[i-1], dest=i, tag=1)\n",
        "              comm.send(B, dest=i, tag=2)\n",
        "\n",
        "          # Calculate its own part of multiplication\n",
        "          C_partial = matrix_multiply(A_chunks[0], B)\n",
        "\n",
        "          # Collect results from worker processes\n",
        "          for i in range(1, size):\n",
        "              C_partial += comm.recv(source=i, tag=3)\n",
        "\n",
        "          # Print the resulting matrix\n",
        "          # print(\"Resulting matrix C:\")\n",
        "          # print(C_partial)\n",
        "      # Worker processes\n",
        "      else:\n",
        "          # Receive matrix chunks from master\n",
        "          A_chunk = comm.recv(source=0, tag=1)\n",
        "          B = comm.recv(source=0, tag=2)\n",
        "\n",
        "          # Perform multiplication\n",
        "          C_partial = matrix_multiply(A_chunk, B)\n",
        "\n",
        "          # Send back the result to master\n",
        "          comm.send(C_partial, dest=0, tag=3)\n",
        "    else:\n",
        "      if rank == 0:\n",
        "        # Generate matrices A and B\n",
        "        A = np.random.rand(N, N)\n",
        "        B = np.random.rand(N, N)\n",
        "        C = matrix_multiply(A, B)\n",
        "    end_time = time.time()\n",
        "    times.append(end_time - start_time)\n",
        "    parallels.append(parallel)\n",
        "    locations.append(location)\n",
        "    print(f\"Execution time: {end_time - start_time} seconds for N = {N} {'parallel' if parallel else 'serial'}\")\n",
        "\n",
        "# end_time = time.time()\n",
        "# times.append(end_time - start_time)\n",
        "# print(f\"Execution time: {end_time - start_time} seconds for N = {N}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Uxf1ePqQ5sAo"
      },
      "outputs": [],
      "source": [
        "# dataframe of times and Ns\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'NxN': Ns * len(parallel_options), 'Time': times, 'Parallelization':parallels, 'Location':locations, 'mpi_size':[size for time in times]})\n",
        "df.to_csv('Results_Google_Colab.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoDGPC8SmauL",
        "outputId": "3e000668-a1c4-420c-afc3-f2b6af323072"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}